{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('cooking_train.json') as raw_data:    \n",
    "    data = json.load(raw_data)\n",
    "\n",
    "for recipe in data:\n",
    "    recipe['cuisine'] = recipe['cuisine'].lower().encode('utf-8')\n",
    "    recipe['ingredients'] = [x.lower().encode('utf-8') for x in recipe['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "import re\n",
    "\n",
    "remove_numbers = re.compile(r\"\\d+\")\n",
    "remove_number_percentage = re.compile(r\"\\d+%\")\n",
    "remove_less_something = re.compile(r\"less [A-z]*\") # i.e. less sodium\n",
    "remove_low_something = re.compile(r\"low [A-z]*\") # i.e. low fat\n",
    "remove_reduced_something = re.compile(r\"reduced [A-z]*\") # i.e. reduced fat\n",
    "remove_no_sth_added = re.compile(r\"no [A-z]+ added\")\n",
    "remove_sth_free = re.compile(r\"[A-z]* free\")\n",
    "remove_parentheses = re.compile(r\"\\([^)]*\\)\")\n",
    "remove_excessive_whitespaces = re.compile(r\" +\")\n",
    "\n",
    "words_to_remove = [\"oz\", \"oz.\", \"cm\", \"centimeter\", \"ounce\", \"gram\", \"g\", \"lb\", \"pound\",\n",
    "                    \"tbsp\", \"tablespoon\", \"ml\", \"mililiter\", \"pint\", \"lowfat\", \"light\",\n",
    "                    \"shredded\", \"skim\", \"nonfat\", \"pure\", \"large\", \"extra large\", \"small\",\n",
    "                    \"medium\", \"fine\", \"free range\", \"vegetarian\", \"natural\", \"low-fat\", \"lean\",\n",
    "                    \"less sodium\", \"drained\", \"washed\", \"homemade\", \"whole wheat\", \"diced\",\n",
    "                    \"washed\", \"chopped\", \"grated\", \"less\", \"lowfat\", \"fresh\", \"low sodium\",\n",
    "                    \"all-purpose\", \"sweetened\", \"unsweetened\", \"condensed\", \"natural\", \"unsalted\",\n",
    "                    \"instant\", \"powdered\", \"unflavored\", \"halves\", \"skim\", \"fine\", \"drained\",\n",
    "                    \"drain\", \"part skim\", \"gourmet\", \"allspice\", \"mix\", \"aged\", \"traditional\",\n",
    "                    \"of\", \"pint\", \"baby\", \"whole-grain\", \"-grain\", \"all\", \"purpose\", \"aritficial\",\n",
    "                    \"back\", \"unbleached\", \"alaskan\", \"alexia\", \"breakstones\", \"kraft\", \"bertolli\", \"best foods\",\n",
    "                    \"betty crocker\", \"bisquick\", \"bob evans\", \"breyers\", \"curry guy\", \"camellia\", \"campbells\", \n",
    "                    \"country crock\", \"crisco\", \"crystal farms\", \"delallo\", \"diamond crystal\", \"domino\", \n",
    "                    \"doritos\", \"earth balance\", \"egglands best\", \"foster farms\", \"franks\", \"gold medal\", \n",
    "                    \"goya\", \"green giant steamers niblets\", \"green giant\", \"heinz\", \"hellmanns\", \"herdez\", \n",
    "                    \"hidden valley\", \"honeysuckle white\", \"jacksonville\",  \"jimmy dean\", \"johnsonville\", \n",
    "                    \"knorr\", \"krudsen\", \"kikkoman\", \"lipton\", \"land o lakes\", \"mazola\", \"lea and perrins\", \n",
    "                    \"mccormick\", \"meyer\", \"mission\", \"old el paso\", \"old bay\", \"pam\", \"pepperidge farm\", \n",
    "                    \"oscar mayer\", \"pace\", \"pillsbury\", \"progresso\", \"pure wesson\", \"pompeian\", \"san marzano\", \n",
    "                    \"sargento\", \"soy vay\", \"taco bell\", \"yoplait\", \"spice islands\", \"stonefire\", \"success\", \n",
    "                    \"swanson\", \"truvÃ­a\", \"uncle bens\", \"wish bone\",\"jameson\", \"tapatio\", \"philadelphia\", \"original\",\n",
    "                    \"homemade\", \"best\", \"good\", \"and\", \"a\", \"of\"]\n",
    "\n",
    "words_to_map = [((\"sea salt\", \"table salt\", \"white salt\", \"kosher salt\"), \"salt\"),\n",
    "               ((\"uncooked\"), \"raw\"),\n",
    "               ((\"black pepper\", \"white pepper\"), \"pepper\"),\n",
    "               ((\"yellow onion\", \"green onion\", \"purple onion\"), \"onion\"),\n",
    "               ((\"white bread\", \"wheat bread\", \"whole-wheat bread\", \"grain bread\"), \"bread\"),\n",
    "               ((\"extra-virgin olive oil\", \"extra virgin olive oil\", \"virgin olive oil\"), \"olive oil\"),\n",
    "               ((\"whie vinegar\"), \"vinegar\"),\n",
    "               ((\"tomatoes\"), \"tomato\"),\n",
    "               ((\"paprikas\"), \"paprika\"),\n",
    "               ((\"eggs\"), \"egg\"),\n",
    "               ((\"mushrooms\"), \"mushroom\"),\n",
    "               ((\"cucumbers\"), \"cucumber\"),\n",
    "               ((\"garlic cloves\"), \"garlic\"),\n",
    "               ((\"carrots\"), \"carrot\"),\n",
    "               ((\"apples\"), \"apple\"),\n",
    "               ((\"spices\"), \"spice\"),\n",
    "               ((\"sausages\"), \"sausage\"),\n",
    "               ((\"potatoes\"), \"potato\"),\n",
    "               ((\"chilies\"), \"chili\"),\n",
    "               ((\"apricots\"), \"apricot\"),\n",
    "               ((\"pounds\"), \"pound\"),\n",
    "               ((\"spinach leaves\"), \"spinach\"),\n",
    "               ((\"radishes\"), \"radish\"),\n",
    "               ((\"cauliflower flowerets\", \"cauliflower florets\", \"cauliflowerets\"), \"cauliflower\"),\n",
    "               ((\"collards\", \"collard green leaves\", \"collard leaves\"), \"collard greens\"),\n",
    "               ((\"basil dried leaves\", \"basil leaves\"), \"basil\"),\n",
    "               ((\"artificial sweetener\"), \"sweetener\")]\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    \n",
    "    ingredient = remove_number_percentage.sub(\"\", ingredient)\n",
    "    ingredient = remove_numbers.sub(\"\", ingredient)\n",
    "    ingredient = remove_less_something.sub(\"\", ingredient)\n",
    "    ingredient = remove_low_something.sub(\"\", ingredient)\n",
    "    ingredient = remove_reduced_something.sub(\"\", ingredient)\n",
    "    ingredient = remove_no_sth_added.sub(\"\", ingredient)\n",
    "    ingredient = remove_sth_free.sub(\"\", ingredient)\n",
    "    ingredient = remove_parentheses.sub(\"\", ingredient)\n",
    "\n",
    "    for word in words_to_remove:\n",
    "        ingredient = re.sub(r\"\\b{}\\b\".format(word), \"\", ingredient)\n",
    "\n",
    "    for words, map_to in words_to_map:\n",
    "        if type(words) is str:\n",
    "            ingredient = re.sub(r\"\\b{}\\b\".format(words), map_to, ingredient)\n",
    "        else:\n",
    "            for entry in words:\n",
    "                ingredient = re.sub(r\"\\b{}\\b\".format(entry), map_to, ingredient)\n",
    "\n",
    "    ingredient = remove_excessive_whitespaces.sub(\" \", ingredient)\n",
    "    ingredient = ingredient.strip() \n",
    "\n",
    "    return ingredient\n",
    "    \n",
    "def process_recipe(recipe):\n",
    "    recipe['ingredients'] = map(process_ingredient, recipe['ingredients'])\n",
    "    \n",
    "    return recipe\n",
    "          \n",
    "prepared_data = np.array(map(process_recipe, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Change recipes to vectorized binary representation of ingredients\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cuisines = []\n",
    "ingredients = []\n",
    "\n",
    "for recipe in prepared_data:\n",
    "    cuisines.append(recipe['cuisine'])\n",
    "    ingredients.extend(recipe['ingredients'])\n",
    "\n",
    "ingredients = np.unique(ingredients)\n",
    "\n",
    "string_recipe_matrix = ['$'.join(recipe['ingredients']) for recipe in prepared_data]\n",
    "\n",
    "count_vectorizer = CountVectorizer(binary=True, token_pattern='[^$]+', vocabulary=ingredients)\n",
    "\n",
    "recipes = count_vectorizer.fit_transform(string_recipe_matrix).toarray()\n",
    "\n",
    "known_ingredients = ingredients\n",
    "\n",
    "# Divide data into train and test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(recipes, cuisines, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy: 0.65 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.74 (+/- 0.00) [linearSVC]\n",
      "Accuracy: 0.76 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Train and test different classifiers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = LinearSVC(multi_class='ovr')\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('svc', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'linearSVC', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load competition test data\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('cooking_test.json') as raw_data:    \n",
    "    data = json.load(raw_data)\n",
    "\n",
    "for recipe in data:\n",
    "    recipe['ingredients'] = [x.lower().encode('utf-8') for x in recipe['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map unknown ingredients to best matching known ingredients\n",
    "\n",
    "import distance\n",
    "\n",
    "def get_best_matching_known_ingredient(ingredient):\n",
    "    for known_ingredient in known_ingredients:\n",
    "        if ingredient in known_ingredient:\n",
    "            return known_ingredient\n",
    "        \n",
    "    for known_ingredient in reversed(known_ingredients):\n",
    "        if known_ingredient in ingredient:\n",
    "            return known_ingredient\n",
    "        \n",
    "    max_dist = 0\n",
    "    \n",
    "    best_match = known_ingredients[0]\n",
    "    \n",
    "    for known_ingredient in known_ingredients:\n",
    "        dist = distance.jaccard(ingredient, known_ingredient)\n",
    "        \n",
    "        if dist > max_dist:\n",
    "            best_match = known_ingredient\n",
    "            max_dist = dist\n",
    "            \n",
    "    return best_match\n",
    "\n",
    "def process_unknown_ingredients(recipe):\n",
    "    recipe['ingredients'] = [ingredient if ingredient in known_ingredients else \n",
    "                             get_best_matching_known_ingredient(ingredient) for ingredient \n",
    "                             in recipe['ingredients'] ]\n",
    "    return recipe\n",
    "\n",
    "prepared_data = np.array(map(process_recipe, data))\n",
    "prepared_data = np.array(map(process_unknown_ingredients, prepared_data))\n",
    "\n",
    "ingredients = []\n",
    "\n",
    "for recipe in prepared_data:\n",
    "    ingredients.extend(recipe['ingredients'])\n",
    "\n",
    "ingredients = np.unique(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFore...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))],\n",
       "         n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "x.extend(X_train)\n",
    "x.extend(X_test)\n",
    "\n",
    "y.extend(Y_train)\n",
    "y.extend(Y_test)\n",
    "\n",
    "eclf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do prediction and save results\n",
    "\n",
    "from pandas import DataFrame\n",
    "from collections import OrderedDict\n",
    "\n",
    "string_recipe_matrix = ['$'.join(recipe['ingredients']) for recipe in prepared_data]\n",
    "\n",
    "count_vectorizer = CountVectorizer(binary=True, token_pattern='[^$]+', vocabulary=known_ingredients)\n",
    "\n",
    "recipes = count_vectorizer.fit_transform(string_recipe_matrix).toarray()\n",
    "\n",
    "prediction_ids = [recipe['id'] for recipe in prepared_data]\n",
    "\n",
    "predictions = eclf.predict(recipes)\n",
    "\n",
    "data_frame = DataFrame(data=OrderedDict([('id', prediction_ids), ('cuisine', predictions)]))\n",
    "\n",
    "data_frame.to_csv('my_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
